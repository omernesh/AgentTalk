---
phase: 02-fastapi-http-server-and-tts-queue
plan: 02
type: execute
wave: 2
depends_on:
  - 02-01
files_modified:
  - agenttalk/tts_worker.py
  - agenttalk/service.py
  - requirements.txt
autonomous: true
requirements:
  - SVC-02
  - SVC-03
  - AUDIO-01
  - AUDIO-04
  - AUDIO-05
  - AUDIO-06
  - TTS-05

must_haves:
  truths:
    - "curl -X POST http://127.0.0.1:5050/speak -H 'Content-Type: application/json' -d '{\"text\":\"Hello world.\"}' returns HTTP 202 and audio plays within 2 seconds"
    - "Sending 10 rapid POST requests to /speak causes at most 3 to be queued; the rest return HTTP 429 without crashing the service"
    - "Audio plays without PortAudio sample rate errors on the Windows 11 test machine (MME device)"
    - "Volume and speed are read from _state dict at synthesis time so they take effect on the next sentence without restart"
    - "POST /speak when service is not yet ready returns HTTP 503"
    - "POST /speak with text that becomes empty after preprocessing returns HTTP 200 with status=skipped"
  artifacts:
    - path: "agenttalk/tts_worker.py"
      provides: "threading.Queue(maxsize=3) + TTS daemon thread consuming sentences, synthesizing, playing audio"
      exports: ["TTS_QUEUE", "STATE", "start_tts_worker"]
    - path: "agenttalk/service.py"
      provides: "POST /speak endpoint wired to preprocessor + TTS queue; WASAPI detection in _configure_audio"
      contains: "@app.post"
  key_links:
    - from: "agenttalk/service.py"
      to: "agenttalk/tts_worker.py"
      via: "from agenttalk.tts_worker import TTS_QUEUE, STATE, start_tts_worker"
      pattern: "from agenttalk\\.tts_worker import"
    - from: "agenttalk/service.py"
      to: "agenttalk/preprocessor.py"
      via: "from agenttalk.preprocessor import preprocess"
      pattern: "from agenttalk\\.preprocessor import"
    - from: "agenttalk/tts_worker.py"
      to: "_kokoro_engine (passed at startup)"
      via: "start_tts_worker(kokoro_engine) call in lifespan"
      pattern: "start_tts_worker"
---

<objective>
Wire the TTS queue, worker thread, and /speak endpoint to complete the full Phase 2 runtime pipeline.

Purpose: Make the service usable — a POST to /speak triggers real speech. This plan connects: HTTP request → text preprocessing → bounded queue → TTS daemon thread → Kokoro synthesis → sounddevice playback. Also applies conditional WASAPI detection (AUDIO-05), volume/speed state (AUDIO-06, TTS-05), and enforces 3-request backpressure (AUDIO-04).

Output: `agenttalk/tts_worker.py` (new) + updated `agenttalk/service.py` with /speak endpoint.
</objective>

<execution_context>
@C:/Users/omern/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/omern/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-fastapi-http-server-and-tts-queue/02-RESEARCH.md
@.planning/phases/02-fastapi-http-server-and-tts-queue/02-01-SUMMARY.md

<interfaces>
<!-- Key types and contracts the executor needs. No codebase exploration needed. -->

From agenttalk/preprocessor.py (created in Plan 01):
```python
def preprocess(text: str) -> list[str]:
    """Full pipeline: strip_markdown → segment_sentences → is_speakable filter.
    Returns list of clean, speakable sentences. May return [] for junk input."""
    ...
```

From agenttalk/service.py (Phase 1 — existing):
```python
# Existing globals (DO NOT RENAME — maintain compatibility):
is_ready: bool = False
_kokoro_engine = None   # Set in _lifespan after _load_and_warmup_kokoro()

# Existing lifespan (EXTEND — do not replace):
@asynccontextmanager
async def _lifespan(app: FastAPI):
    global is_ready, _kokoro_engine
    _configure_audio()             # ← extend this function (WASAPI detection)
    _kokoro_engine = _load_and_warmup_kokoro()
    is_ready = True
    # ... startup audio proof ...
    yield

# Existing FastAPI app:
app = FastAPI(lifespan=_lifespan)
```

From 02-RESEARCH.md (Pattern 1 — threading.Queue bounded backpressure):
```python
# tts_worker.py — standalone module
import queue, threading, logging, sounddevice as sd, numpy as np

TTS_QUEUE: queue.Queue = queue.Queue(maxsize=3)

STATE: dict = {
    "volume": 1.0,   # 0.0–2.0 (>1.0 → clip with np.clip)
    "speed":  1.0,   # 0.5–2.0
    "voice":  "af_heart",
    "muted":  False, # skip synthesis when True (future Phase 4 use)
}

def start_tts_worker(kokoro_engine) -> threading.Thread:
    """Start TTS daemon thread. Call from lifespan after model is loaded."""
    t = threading.Thread(
        target=_tts_worker,
        args=(kokoro_engine,),
        daemon=True,
        name="tts-worker",
    )
    t.start()
    logging.info("TTS worker daemon thread started.")
    return t

def _tts_worker(kokoro_engine) -> None:
    logging.info("TTS worker thread started.")
    while True:
        sentences: list[str] = TTS_QUEUE.get()
        try:
            for sentence in sentences:
                if not sentence.strip() or STATE["muted"]:
                    continue
                logging.debug("TTS: synthesizing %r", sentence[:60])
                samples, rate = kokoro_engine.create(
                    sentence,
                    voice=STATE["voice"],
                    speed=STATE["speed"],
                    lang="en-us",
                )
                scaled = samples * STATE["volume"]
                if STATE["volume"] > 1.0:
                    scaled = np.clip(scaled, -1.0, 1.0)
                sd.play(scaled, samplerate=rate)
                sd.wait()
        except Exception:
            logging.exception("TTS worker error on sentence.")
        finally:
            TTS_QUEUE.task_done()
```

From 02-RESEARCH.md (Pattern 6 — WASAPI host API detection):
```python
def _configure_audio() -> None:
    """Detect host API and apply WasapiSettings only if WASAPI device."""
    try:
        device_info = sd.query_devices(kind='output')
        hostapi_id = device_info.get('hostapi', 0)
        hostapi_info = sd.query_hostapis(hostapi_id)
        hostapi_name = hostapi_info.get('name', '').upper()
        if 'WASAPI' in hostapi_name:
            sd.default.extra_settings = sd.WasapiSettings(auto_convert=True)
            logging.info("WASAPI device detected — auto_convert enabled.")
        else:
            logging.info(
                "Non-WASAPI device (%s) — using PortAudio default resampling.", hostapi_name
            )
    except Exception:
        logging.warning("Could not detect host API; using PortAudio defaults.", exc_info=True)
```

From 02-RESEARCH.md (Pattern 7 — Pydantic /speak endpoint):
```python
from pydantic import BaseModel
from fastapi.responses import JSONResponse
import queue

class SpeakRequest(BaseModel):
    text: str

@app.post("/speak", status_code=202)
async def speak(req: SpeakRequest):
    if not is_ready:
        return JSONResponse({"status": "not_ready"}, status_code=503)

    from agenttalk.preprocessor import preprocess  # already installed in Plan 01
    sentences = preprocess(req.text)

    if not sentences:
        return JSONResponse({"status": "skipped", "reason": "no speakable sentences"}, status_code=200)

    try:
        TTS_QUEUE.put_nowait(sentences)
        return JSONResponse({"status": "queued", "sentences": len(sentences)}, status_code=202)
    except queue.Full:
        logging.info("TTS queue full — dropping /speak request.")
        return JSONResponse({"status": "dropped", "reason": "queue full"}, status_code=429)
```

CRITICAL — DO NOT USE asyncio.Queue: threading.Queue is the correct choice.
asyncio.Queue is NOT thread-safe and MUST NOT be used as the bridge between the
async FastAPI handler and the threading.Thread TTS worker. (Research pitfall #1.)

CRITICAL — DO NOT call kokoro.create() in the async handler: Synthesis is
CPU-bound blocking work. It must run only in the TTS daemon thread. The handler
only preprocesses + enqueues. (Research pitfall #2.)
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create tts_worker.py with bounded queue and TTS daemon thread</name>
  <files>agenttalk/tts_worker.py</files>
  <action>
    Create `agenttalk/tts_worker.py` as a standalone module. Implement exactly the pattern from the interfaces section above:

    - `TTS_QUEUE: queue.Queue = queue.Queue(maxsize=3)` — module-level, thread-safe, bounded at 3 requests
    - `STATE: dict` with keys: volume (1.0), speed (1.0), voice ("af_heart"), muted (False)
    - `start_tts_worker(kokoro_engine) -> threading.Thread` — creates and starts daemon thread named "tts-worker"
    - `_tts_worker(kokoro_engine) -> None` — infinite loop: get() from queue, synthesize each sentence, play scaled audio

    In the worker loop:
    - Skip sentence if STATE["muted"] is True (sets up Phase 4 mute toggle without refactor)
    - Apply volume: `scaled = samples * STATE["volume"]`
    - Clip if volume > 1.0: `np.clip(scaled, -1.0, 1.0)` to avoid speaker damage
    - Call `sd.play(scaled, samplerate=rate)` then `sd.wait()` — both mandatory
    - Wrap synthesis in try/except, always call `TTS_QUEUE.task_done()` in finally

    Import numpy as `import numpy as np` at module top (already installed as kokoro-onnx dep).
    DO NOT use asyncio.Queue — threading.Queue only.
    DO NOT call kokoro.create() anywhere except in _tts_worker().
  </action>
  <verify>
    ```bash
    cd /d/docker/claudetalk && python -c "from agenttalk.tts_worker import TTS_QUEUE, STATE, start_tts_worker; print('TTS_QUEUE maxsize:', TTS_QUEUE.maxsize); print('STATE keys:', list(STATE.keys()))"
    ```
    Output shows `TTS_QUEUE maxsize: 3` and STATE keys include volume, speed, voice, muted.
  </verify>
  <done>
    agenttalk/tts_worker.py imports cleanly. TTS_QUEUE.maxsize == 3. STATE dict has 4 keys (volume, speed, voice, muted). Module exports TTS_QUEUE, STATE, start_tts_worker.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add /speak endpoint and wire WASAPI detection into service.py</name>
  <files>agenttalk/service.py</files>
  <action>
    Modify `agenttalk/service.py` to add the /speak endpoint and extend _configure_audio().
    DO NOT rewrite the file — make targeted additions/modifications only.

    **Step 1: Replace _configure_audio() body** with the WASAPI detection pattern from the interfaces section.
    The current implementation only queries and logs the device. Replace it with the version that conditionally applies `sd.WasapiSettings(auto_convert=True)` only when host API is WASAPI.
    Keep the same function signature: `def _configure_audio() -> None:`.

    **Step 2: Add imports at top of file** (after existing imports):
    ```python
    import queue
    import numpy as np
    from agenttalk.tts_worker import TTS_QUEUE, STATE, start_tts_worker
    from pydantic import BaseModel
    ```

    **Step 3: Add SpeakRequest model** before the FastAPI app's /health endpoint:
    ```python
    class SpeakRequest(BaseModel):
        text: str
    ```

    **Step 4: Extend _lifespan()** — after `is_ready = True` and before `yield`, add:
    ```python
    start_tts_worker(_kokoro_engine)
    logging.info("TTS worker started.")
    ```
    This must go BEFORE the startup audio proof block (worker needs to be running, though startup audio can still use play_audio() directly — that's fine for Phase 1 compatibility).

    **Step 5: Add /speak POST endpoint** after the /health GET endpoint:
    ```python
    @app.post("/speak", status_code=202)
    async def speak(req: SpeakRequest):
        """Accept text, preprocess, and queue for TTS playback."""
        if not is_ready:
            return JSONResponse({"status": "not_ready"}, status_code=503)

        from agenttalk.preprocessor import preprocess
        sentences = preprocess(req.text)

        if not sentences:
            return JSONResponse(
                {"status": "skipped", "reason": "no speakable sentences"},
                status_code=200,
            )

        try:
            TTS_QUEUE.put_nowait(sentences)
            return JSONResponse(
                {"status": "queued", "sentences": len(sentences)},
                status_code=202,
            )
        except queue.Full:
            logging.info("TTS queue full (%d items) — dropping /speak request.", TTS_QUEUE.qsize())
            return JSONResponse(
                {"status": "dropped", "reason": "queue full"},
                status_code=429,
            )
    ```

    Ensure `pydantic` is available (it's a FastAPI dependency, already installed). No new pip install needed for service.py changes.
  </action>
  <verify>
    **Step 1 — Static import check:**
    ```bash
    cd /d/docker/claudetalk && python -c "import agenttalk.service; print('service imports OK')"
    ```
    Prints "service imports OK" without error.

    **Step 2 — Live endpoint test (start service in background first):**
    ```bash
    cd /d/docker/claudetalk && python agenttalk/service.py &
    sleep 8
    curl -s -X POST http://127.0.0.1:5050/speak -H "Content-Type: application/json" -d "{\"text\":\"Hello from Phase 2.\"}"
    ```
    Response contains `"status": "queued"` and audio plays through speakers.

    **Step 3 — Queue full test (10 rapid requests):**
    ```bash
    for i in $(seq 1 10); do curl -s -X POST http://127.0.0.1:5050/speak -H "Content-Type: application/json" -d "{\"text\":\"Sentence $i is being spoken right now.\"}" & done; wait
    ```
    Some responses show `"status": "dropped"` with status_code 429. Service does not crash.

    **Step 4 — Junk input test:**
    ```bash
    curl -s -X POST http://127.0.0.1:5050/speak -H "Content-Type: application/json" -d "{\"text\":\"{\\\"key\\\": \\\"value\\\"}\"}"
    ```
    Response contains `"status": "skipped"`.
  </verify>
  <done>
    service.py imports cleanly. POST /speak returns 202 + queues audio. POST /speak with junk returns 200 skipped. 10 rapid requests produce some 429 dropped responses. Audio plays through speakers on a valid request. Log shows "WASAPI" or "Non-WASAPI device" detection line at startup.
  </done>
</task>

</tasks>

<verification>
Overall Phase 2 verification. Run after both tasks complete:

**1. Full pipeline smoke test:**
```bash
cd /d/docker/claudetalk && python agenttalk/service.py &
sleep 8
curl -s http://127.0.0.1:5050/health
curl -s -X POST http://127.0.0.1:5050/speak -H "Content-Type: application/json" -d '{"text":"Hello world. This is a test of the Phase 2 speak endpoint."}'
```
Health returns 200. Speak returns 202. Audio plays.

**2. Markdown preprocessing (AUDIO-02):**
```bash
curl -s -X POST http://127.0.0.1:5050/speak -H "Content-Type: application/json" \
  -d '{"text":"Here is some code: ```python\nprint(\"hello\")\n``` And a URL https://example.com and **bold** text."}'
```
Audio plays only the prose text — no code, no URL spoken.

**3. Junk filter (AUDIO-03):**
```bash
curl -s -X POST http://127.0.0.1:5050/speak -H "Content-Type: application/json" -d '{"text":"{\"status\": 200, \"data\": null}"}'
```
Returns `{"status": "skipped"}`. No audio.

**4. Backpressure (AUDIO-04):**
```bash
for i in $(seq 1 10); do curl -s -X POST http://127.0.0.1:5050/speak -H "Content-Type: application/json" -d "{\"text\":\"This is sentence number $i being tested.\"}" & done; wait
```
Mix of 202 (queued) and 429 (dropped) responses. At most 3 queued. No crash.

**5. WASAPI detection log (AUDIO-05):**
```bash
grep -i "wasapi\|MME\|non-wasapi\|portaudio" "$APPDATA/AgentTalk/agenttalk.log"
```
Log shows device detection line: either "WASAPI device detected" or "Non-WASAPI device (MME)".

**6. Preprocessor tests still pass (Plan 01 regression):**
```bash
cd /d/docker/claudetalk && python -m pytest tests/test_preprocessor.py -v
```
All pass.
</verification>

<success_criteria>
- POST /speak on a running service returns 202 and speaks the text within 2 seconds (Phase 2 goal criterion #1)
- Markdown text is preprocessed before synthesis (criterion #2)
- JSON/symbol-only text returns 200 skipped, no audio (criterion #3)
- 10 rapid requests result in at most 3 queued; rest return 429 (criterion #4)
- Log contains WASAPI/MME detection line at startup — no PaErrorCode -9984 errors (criterion #5)
- agenttalk/tts_worker.py exists with TTS_QUEUE, STATE, start_tts_worker exports
- service.py contains @app.post("/speak") route
- All Plan 01 preprocessor tests continue to pass
</success_criteria>

<output>
After completion, create `.planning/phases/02-fastapi-http-server-and-tts-queue/02-02-SUMMARY.md`
</output>
