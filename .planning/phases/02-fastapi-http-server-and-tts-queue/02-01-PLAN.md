---
phase: 02-fastapi-http-server-and-tts-queue
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - agenttalk/preprocessor.py
  - tests/test_preprocessor.py
autonomous: true
requirements:
  - AUDIO-02
  - AUDIO-03

must_haves:
  truths:
    - "strip_markdown() removes fenced code blocks, inline code, URLs, file paths, markdown headers, bold/italic, blockquotes, and list bullets from input text"
    - "is_speakable() returns False for sentences with fewer than 40% alphabetic characters (e.g. pure JSON, symbol strings)"
    - "is_speakable() returns True for normal English prose"
    - "preprocess() applies strip_markdown then segment_sentences then is_speakable filter, returning only clean speakable sentences"
    - "Fenced code blocks are stripped before inline code (order-dependent correctness)"
  artifacts:
    - path: "agenttalk/preprocessor.py"
      provides: "strip_markdown(), segment_sentences(), is_speakable(), preprocess() functions"
      exports: ["strip_markdown", "segment_sentences", "is_speakable", "preprocess"]
    - path: "tests/test_preprocessor.py"
      provides: "pytest test suite for all four functions"
      contains: "def test_"
  key_links:
    - from: "tests/test_preprocessor.py"
      to: "agenttalk/preprocessor.py"
      via: "from agenttalk.preprocessor import strip_markdown, is_speakable, preprocess"
      pattern: "from agenttalk\\.preprocessor import"
---

<objective>
TDD implementation of the text preprocessing module for TTS readiness.

Purpose: Clean assistant text before synthesis — strip markdown formatting, segment into sentences, and filter out non-speakable noise (JSON, symbol strings, code that slipped through). This module is the input gate for all TTS audio. Getting the preprocessing correct avoids reading garbage through speakers.

Output: `agenttalk/preprocessor.py` with four tested functions + `tests/test_preprocessor.py` passing RED-GREEN-REFACTOR cycle.
</objective>

<execution_context>
@C:/Users/omern/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/omern/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-fastapi-http-server-and-tts-queue/02-RESEARCH.md

<interfaces>
<!-- Key patterns from research — no codebase exploration needed. -->

From 02-RESEARCH.md (Pattern 2 — Text Preprocessing Pipeline):
```python
import re

def strip_markdown(text: str) -> str:
    # ORDER IS CRITICAL: fenced blocks BEFORE inline code
    text = re.sub(r'```[\s\S]*?```', ' ', text)           # fenced code blocks
    text = re.sub(r'`[^`\n]+`', ' ', text)                 # inline code
    text = re.sub(r'https?://\S+', ' ', text)               # URLs
    text = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', text)   # [link text](url)
    text = re.sub(r'^#{1,6}\s+', '', text, flags=re.MULTILINE)  # headers
    text = re.sub(r'[*_]{1,3}([^*_\n]+)[*_]{1,3}', r'\1', text)  # bold/italic
    text = re.sub(r'^>\s+', '', text, flags=re.MULTILINE)   # blockquotes
    text = re.sub(r'^[-*+]\s+', '', text, flags=re.MULTILINE)  # list bullets
    text = re.sub(r'\s+', ' ', text).strip()                # normalize whitespace
    return text
```

From 02-RESEARCH.md (Pattern 3 — Sentence Segmentation):
```python
import pysbd

_segmenter = pysbd.Segmenter(language="en", clean=False)

def segment_sentences(text: str) -> list[str]:
    return _segmenter.segment(text)
```

From 02-RESEARCH.md (Pattern 4 — Alphabetic Ratio Filter):
```python
def is_speakable(sentence: str) -> bool:
    cleaned = sentence.strip()
    if not cleaned:
        return False
    alpha_count = sum(c.isalpha() for c in cleaned)
    return alpha_count / len(cleaned) >= 0.40
```

New composite function (not in research, derive from patterns):
```python
def preprocess(text: str) -> list[str]:
    """Full pipeline: strip → segment → filter. Returns speakable sentences."""
    cleaned = strip_markdown(text)
    sentences = segment_sentences(cleaned)
    return [s for s in sentences if is_speakable(s)]
```

pysbd thread safety note (from research open question #1):
- Create pysbd.Segmenter() per call inside segment_sentences() to avoid shared mutable state.
- This is safer than a module-level singleton for concurrent access.
- Cost: negligible (pure Python, no model load).
</interfaces>
</context>

<feature>
  <name>Text Preprocessing Pipeline</name>
  <files>agenttalk/preprocessor.py, tests/test_preprocessor.py</files>
  <behavior>
    strip_markdown(text) cases:
    - "```python\ncode\n```" → " " (fenced code block stripped)
    - "Use `foo()` to call" → "Use  to call" (inline code stripped)
    - "Visit https://example.com now" → "Visit  now" (URL stripped)
    - "[link text](https://example.com)" → "link text" (keep text, drop URL)
    - "## Section Header" → "Section Header" (header marker stripped)
    - "**bold text**" → "bold text" (bold markers stripped)
    - "*italic text*" → "italic text" (italic markers stripped)
    - "> quoted line" → "quoted line" (blockquote stripped)
    - "- list item" → "list item" (bullet stripped)
    - "Hello  world" → "Hello world" (whitespace normalized)
    - Fenced block containing backtick: entire block removed first (order test)

    is_speakable(sentence) cases:
    - "Hello world" → True (100% alpha)
    - "The quick brown fox." → True (>40% alpha)
    - "{}" → False (0% alpha)
    - '{"key": "value"}' → False (<40% alpha — symbols dominate)
    - "1234567890" → False (0% alpha)
    - "" → False (empty)
    - "   " → False (whitespace only)
    - "abc!" → True (75% alpha — 3/4 chars alphabetic)

    preprocess(text) cases:
    - "Hello world. **Goodbye**." → ["Hello world.", "Goodbye."] (clean split)
    - "Hello.\n```\ncode\n```\nGoodbye." → ["Hello.", "Goodbye."] (code block removed, prose kept)
    - '{"key": "value"}' → [] (junk filtered)
    - "" → [] (empty input)
    - "Visit https://example.com for more info." → ["Visit  for more info."] (URL stripped, still speakable)
  </behavior>
  <implementation>
    1. Create tests/test_preprocessor.py first (RED phase). Write tests for all cases above.
       Use pytest parametrize where possible. The tests must FAIL on import (file doesn't exist yet).
    2. Create agenttalk/preprocessor.py with strip_markdown, segment_sentences, is_speakable, preprocess.
       Install pysbd: pip install pysbd==0.3.4
       Add pysbd==0.3.4 to requirements.txt.
       Create pysbd.Segmenter per call in segment_sentences (thread safety — see research open question #1).
    3. Run tests (GREEN phase). All must pass.
    4. No refactor needed if GREEN passes cleanly.
  </implementation>
</feature>

<verification>
Run after implementation:
```bash
cd /d/docker/claudetalk && python -m pytest tests/test_preprocessor.py -v
```
All tests pass. No test skipped.

Also verify import works from service context:
```bash
cd /d/docker/claudetalk && python -c "from agenttalk.preprocessor import strip_markdown, is_speakable, preprocess; print('OK')"
```
Prints "OK".
</verification>

<success_criteria>
- tests/test_preprocessor.py exists with ≥10 test cases covering strip_markdown, is_speakable, and preprocess
- agenttalk/preprocessor.py exists and exports strip_markdown, segment_sentences, is_speakable, preprocess
- `python -m pytest tests/test_preprocessor.py -v` exits 0 with all tests passing
- `pip install pysbd==0.3.4` is run and pysbd==0.3.4 appears in requirements.txt
- Fenced code block test explicitly verifies block removed before inline code (order test)
- is_speakable('{"key": "value"}') returns False (JSON filtered)
- preprocess("Hello.\n```\ncode\n```\nGoodbye.") returns both prose sentences
</success_criteria>

<output>
After completion, create `.planning/phases/02-fastapi-http-server-and-tts-queue/02-01-SUMMARY.md`
</output>
